# üåç Classifica√ß√£o de Alertas de Terremoto: Uma An√°lise Comparativa entre Modelos K-NN e SVC

---

## üéØ Objetivo do Projeto

Este projeto de Machine Learning visa **comparar a efic√°cia** dos algoritmos **K-Nearest Neighbors (KNN)** e **Support Vector Machine (SVC) com kernel linear** na classifica√ß√£o dos diferentes n√≠veis de alerta (multi-classe) de um dataset de terremotos.

O foco √© analisar a rela√ß√£o entre a complexidade do modelo (abordagem local vs. global) e as m√©tricas de desempenho (**Acur√°cia** e **F1-Score**), demonstrando qual abordagem √© mais adequada para prever alertas s√≠smicos.

### Informa√ß√µes do Trabalho

| Atribui√ß√µes | Detalhes |
| :--- | :--- |
| **Institui√ß√£o** | FATEC SHUNJI NISHIMURA |
| **Autores** | Bernardo Braga Bomfim, Eduardo Ribeiro de Morais |
| **Ano** | 2025 |

---

## üìö Dataset: Alertas de Terremoto

O experimento utilizou o dataset de alertas de terremoto para a tarefa de classifica√ß√£o multiclasse.

### Fonte e Link
| Detalhe | Valor |
| :--- | :--- |
| **Nome do Arquivo** | `earthquake_alert_balanced_dataset.csv` |
| **Plataforma** | Kaggle |
| **URL** | [https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset](https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset) |

### Caracter√≠sticas do Dataset

* **Tamanho:** 1300 entradas.
* **Integridade:** Todas as colunas num√©ricas est√£o completas (sem valores nulos).
* **Alvo:** `alert` (n√≠vel de alerta - classifica√ß√£o multiclasse).
* **Colunas Principais:**
    * `magnitude`: intensidade do terremoto (float64).
    * `depth`: profundidade do evento em km (float64).
    * `cdi`: √≠ndice de intensidade percebida (float64).
    * `mmi`: √≠ndice de intensidade modificada (float64).
    * `sig`: n√≠vel de signific√¢ncia do evento (float64).

---

## üõ†Ô∏è Tecnologias e Stack

O projeto est√° contido em um **Jupyter Notebook**, garantindo a reprodutibilidade e documenta√ß√£o interativa.

| Componente | Ferramenta/Biblioteca | Vers√£o | Fun√ß√£o |
| :--- | :--- | :--- | :--- |
| **Linguagem** | Python | 3.13 | Linguagem de programa√ß√£o central. |
| **Dados** | Pandas | 2.3.3 | Manipula√ß√£o e leitura do dataset. |
| **Machine Learning** | Scikit-learn | 1.7.2 | Treinamento, pr√©-processamento (`StandardScaler`, `LabelEncoder`) e avalia√ß√£o de modelos. |
| **Visualiza√ß√£o** | Matplotlib & Seaborn | 3.10.6 & 0.13.2 | Cria√ß√£o de gr√°ficos, como Matrizes de Confus√£o e compara√ß√£o de m√©tricas. |

---

## üß™ Metodologia e Modelos

O experimento de classifica√ß√£o foi conduzido em tr√™s etapas: **Pr√©-processamento**, **Treinamento e Predi√ß√£o**, e **Avalia√ß√£o**.

### 1. Pr√©-processamento

* **Codifica√ß√£o:** A coluna alvo (`alert`) foi convertida de nominal para num√©rica (`LabelEncoder`).
* **Divis√£o:** O dataset foi dividido em conjuntos de **Treino (80%)** e **Teste (20%)** com estrat√©gia estratificada (`stratify=y`).
* **Normaliza√ß√£o:** As caracter√≠sticas foram padronizadas (`StandardScaler`) para otimizar modelos baseados em dist√¢ncia.

### 2. Modelos em Compara√ß√£o

| Modelo | Descri√ß√£o | Configura√ß√£o Principal | Hip√≥tese |
| :--- | :--- | :--- | :--- |
| **K-Nearest Neighbors (KNN)** | Classificador baseado em inst√¢ncia. A classifica√ß√£o √© feita pela maioria de `k` vizinhos mais pr√≥ximos. | `n_neighbors=5` | Esperado um bom desempenho, pois a normaliza√ß√£o otimiza a m√©trica de dist√¢ncia para padr√µes agrupados. |
| **Support Vector Machine (SVC)** | Classificador que busca um hiperplano de separa√ß√£o. | `kernel='linear'` | Escolhido para avaliar se a rela√ß√£o entre as vari√°veis e o alerta √© linearmente separ√°vel. |

### 3. M√©tricas de Avalia√ß√£o

As seguintes m√©tricas foram utilizadas para a compara√ß√£o:

* **Acur√°cia (Accuracy):** Propor√ß√£o de previs√µes corretas sobre o total.
* **F1-Score (M√©dia Ponderada):** M√©dia harm√¥nica de Precis√£o e Recall. √â a m√©trica principal por ser mais robusta em classifica√ß√µes multi-classe, equilibrando falsos positivos e falsos negativos.

---

## üìà Resultados e Conclus√£o

### Compara√ß√£o de Desempenho

O modelo **K-Nearest Neighbors (KNN)** demonstrou um desempenho significativamente superior ao **SVC (Linear)**.

| Modelo | Acur√°cia | F1-Score |
| :--- | :--- | :--- |
| **KNN (k=5)** | **0.84** | **0.84** |
| **SVC (Linear)** | 0.67 | 0.66 |

* **KNN:** Apresentou a maior parte das classifica√ß√µes corretas (concentrada na diagonal da Matriz de Confus√£o), com erro aceit√°vel (maioria dos erros sendo "falsos positivos de risco" na classe C0).
* **SVC (Linear):** Demonstrou dificuldades cr√≠ticas, especialmente nas classes C1 e C3, com alta incid√™ncia de Falsos Negativos.

### Conclus√£o Principal

O experimento demonstrou que o problema de classifica√ß√£o de alertas de terremoto neste conjunto de dados **n√£o √© linearmente separ√°vel**. O modelo baseado em proximidade local (**KNN**) foi capaz de capturar a estrutura n√£o-linear dos dados e modelar as fronteiras de decis√£o com muito mais efic√°cia.

---

## üí° Sugest√µes para Trabalhos Futuros

Para aprimorar o estudo, sugerimos as seguintes melhorias:

1.  **Hyperparameter Tuning:** Otimizar o KNN testando diferentes valores de $k$ (al√©m de $k=5$) e m√©tricas de dist√¢ncia.
2.  **Kernel N√£o-Linear para SVC:** Reavaliar o SVC utilizando um kernel n√£o-linear, como o **RBF (Radial Basis Function)**, para verificar se ele pode superar o KNN ao mapear rela√ß√µes complexas.
3.  **An√°lise de Features:** Aplicar t√©cnicas de Feature Selection para determinar se a remo√ß√£o de vari√°veis de baixa relev√¢ncia pode simplificar o modelo e melhorar o desempenho.